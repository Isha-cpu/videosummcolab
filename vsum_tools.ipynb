{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaNbzCF8i5own4vTjHw39p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyegupta12/videosummcolab/blob/main/vsum_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMcNn4Is96jT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from knapsack import knapsack_dp\n",
        "from knapsack import knapsack_ortools\n",
        "import math\n",
        "\n",
        "\n",
        "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
        "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
        "    Args:\n",
        "    ---------------------------------------------\n",
        "    - ypred: predicted importance scores.\n",
        "    - cps: change points, 2D matrix, each row contains a segment.\n",
        "    - n_frames: original number of frames.\n",
        "    - nfps: number of frames per segment.\n",
        "    - positions: positions of subsampled frames in the original video.\n",
        "    - proportion: length of video summary (compared to original video length).\n",
        "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
        "    \"\"\"\n",
        "    n_segs = cps.shape[0]\n",
        "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
        "    if positions.dtype != int:\n",
        "        positions = positions.astype(np.int32)\n",
        "    if positions[-1] != n_frames:\n",
        "        positions = np.concatenate([positions, [n_frames]])\n",
        "    for i in range(len(positions) - 1):\n",
        "        pos_left, pos_right = positions[i], positions[i+1]\n",
        "        if i == len(ypred):\n",
        "            frame_scores[pos_left:pos_right] = 0\n",
        "        else:\n",
        "            frame_scores[pos_left:pos_right] = ypred[i]\n",
        "\n",
        "    seg_score = []\n",
        "    for seg_idx in range(n_segs):\n",
        "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
        "        scores = frame_scores[start:end]\n",
        "        seg_score.append(float(scores.mean()))\n",
        "\n",
        "    limits = int(math.floor(n_frames * proportion))\n",
        "\n",
        "    if method == 'knapsack':\n",
        "        #picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
        "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
        "    elif method == 'rank':\n",
        "        order = np.argsort(seg_score)[::-1].tolist()\n",
        "        picks = []\n",
        "        total_len = 0\n",
        "        for i in order:\n",
        "            if total_len + nfps[i] < limits:\n",
        "                picks.append(i)\n",
        "                total_len += nfps[i]\n",
        "    else:\n",
        "        raise KeyError(\"Unknown method {}\".format(method))\n",
        "\n",
        "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
        "    for seg_idx in range(n_segs):\n",
        "        nf = nfps[seg_idx]\n",
        "        if seg_idx in picks:\n",
        "            tmp = np.ones((nf), dtype=np.float32)\n",
        "        else:\n",
        "            tmp = np.zeros((nf), dtype=np.float32)\n",
        "        summary = np.concatenate((summary, tmp))\n",
        "\n",
        "    summary = np.delete(summary, 0) # delete the first element\n",
        "    return summary\n",
        "\n",
        "\n",
        "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
        "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
        "    Args:\n",
        "    --------------------------------\n",
        "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
        "    eval_metric = {'avg', 'max'}\n",
        "    'avg' averages results of comparing multiple human summaries.\n",
        "    'max' takes the maximum (best) out of multiple comparisons.\n",
        "    \"\"\"\n",
        "    machine_summary = machine_summary.astype(np.float32)\n",
        "    user_summary = user_summary.astype(np.float32)\n",
        "    n_users,n_frames = user_summary.shape\n",
        "\n",
        "    # binarization\n",
        "    machine_summary[machine_summary > 0] = 1\n",
        "    user_summary[user_summary > 0] = 1\n",
        "\n",
        "    if len(machine_summary) > n_frames:\n",
        "        machine_summary = machine_summary[:n_frames]\n",
        "    elif len(machine_summary) < n_frames:\n",
        "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
        "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
        "\n",
        "    f_scores = []\n",
        "    prec_arr = []\n",
        "    rec_arr = []\n",
        "\n",
        "    for user_idx in range(n_users):\n",
        "        gt_summary = user_summary[user_idx,:]\n",
        "        overlap_duration = (machine_summary * gt_summary).sum()\n",
        "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
        "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
        "        if precision == 0 and recall == 0:\n",
        "            f_score = 0.\n",
        "        else:\n",
        "            f_score = (2 * precision * recall) / (precision + recall)\n",
        "        f_scores.append(f_score)\n",
        "        prec_arr.append(precision)\n",
        "        rec_arr.append(recall)\n",
        "\n",
        "    if eval_metric == 'avg':\n",
        "        final_f_score = np.mean(f_scores)\n",
        "        final_prec = np.mean(prec_arr)\n",
        "        final_rec = np.mean(rec_arr)\n",
        "    elif eval_metric == 'max':\n",
        "        final_f_score = np.max(f_scores)\n",
        "        max_idx = np.argmax(f_scores)\n",
        "        final_prec = prec_arr[max_idx]\n",
        "        final_rec = rec_arr[max_idx]\n",
        "\n",
        "    return final_f_score, final_prec, final_rec\n",
        "\n",
        "\n",
        "def evaluate_user_summaries(user_summary, eval_metric='avg'):\n",
        "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
        "    Args:\n",
        "    --------------------------------\n",
        "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
        "    eval_metric = {'avg', 'max'}\n",
        "    'avg' averages results of comparing multiple human summaries.\n",
        "    'max' takes the maximum (best) out of multiple comparisons.\n",
        "    \"\"\"\n",
        "    user_summary = user_summary.astype(np.float32)\n",
        "    n_users, n_frames = user_summary.shape\n",
        "\n",
        "    # binarization\n",
        "    user_summary[user_summary > 0] = 1\n",
        "\n",
        "    f_scores = []\n",
        "    prec_arr = []\n",
        "    rec_arr = []\n",
        "\n",
        "    for user_idx in range(n_users):\n",
        "        gt_summary = user_summary[user_idx, :]\n",
        "        for other_user_idx in range(user_idx+1, n_users):\n",
        "            other_gt_summary = user_summary[other_user_idx, :]\n",
        "            overlap_duration = (other_gt_summary * gt_summary).sum()\n",
        "            precision = overlap_duration / (other_gt_summary.sum() + 1e-8)\n",
        "            recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
        "            if precision == 0 and recall == 0:\n",
        "                f_score = 0.\n",
        "            else:\n",
        "                f_score = (2 * precision * recall) / (precision + recall)\n",
        "            f_scores.append(f_score)\n",
        "            prec_arr.append(precision)\n",
        "            rec_arr.append(recall)\n",
        "\n",
        "\n",
        "    if eval_metric == 'avg':\n",
        "        final_f_score = np.mean(f_scores)\n",
        "        final_prec = np.mean(prec_arr)\n",
        "        final_rec = np.mean(rec_arr)\n",
        "    elif eval_metric == 'max':\n",
        "        final_f_score = np.max(f_scores)\n",
        "        max_idx = np.argmax(f_scores)\n",
        "        final_prec = prec_arr[max_idx]\n",
        "        final_rec = rec_arr[max_idx]\n",
        "\n",
        "    return final_f_score, final_prec, final_rec"
      ]
    }
  ]
}