{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+/OChJpPiJDFBl9uwbILX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyegupta12/videosummcolab/blob/main/create_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMtYTx6k7oy-"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import os.path as osp\n",
        "import argparse\n",
        "import h5py\n",
        "import math\n",
        "import numpy as np\n",
        "import errno\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(\"Code to create splits in json form\")\n",
        "parser.add_argument('-d', '--dataset', type=str, required=True, help=\"path to h5 dataset (required)\")\n",
        "parser.add_argument('--save-dir', type=str, default='datasets', help=\"path to save output json file (default: 'datasets/')\")\n",
        "parser.add_argument('--save-name', type=str, default='splits', help=\"name to save as, excluding extension (default: 'splits')\")\n",
        "parser.add_argument('--num-splits', type=int, default=5, help=\"how many splits to generate (default: 5)\")\n",
        "parser.add_argument('--train-percent', type=float, default=0.8, help=\"percentage of training data (default: 0.8)\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "def mkdir_if_missing(directory):\n",
        "    if not osp.exists(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "def write_json(obj, fpath):\n",
        "    mkdir_if_missing(osp.dirname(fpath))\n",
        "    with open(fpath, 'w') as f:\n",
        "        json.dump(obj, f, indent=4, separators=(',', ': '))\n",
        "\n",
        "\n",
        "def split_random(keys, num_videos, num_train):\n",
        "    \"\"\"Random split\"\"\"\n",
        "    train_keys, test_keys = [], []\n",
        "    rnd_idxs = np.random.choice(range(num_videos), size=num_train, replace=False)\n",
        "    for key_idx, key in enumerate(keys):\n",
        "        if key_idx in rnd_idxs:\n",
        "            train_keys.append(key)\n",
        "        else:\n",
        "            test_keys.append(key)\n",
        "\n",
        "    assert len(set(train_keys) & set(test_keys)) == 0, \"Error: train_keys and test_keys overlap\"\n",
        "\n",
        "    return train_keys, test_keys\n",
        "\n",
        "def create():\n",
        "    print(\"==========\\nArgs:{}\\n==========\".format(args))\n",
        "    print(\"Goal: randomly split data for {} times, {:.1%} for training and the rest for testing\".format(args.num_splits, args.train_percent))\n",
        "    print(\"Loading dataset from {}\".format(args.dataset))\n",
        "    dataset = h5py.File(args.dataset, 'r')\n",
        "    keys = dataset.keys()\n",
        "    num_videos = len(keys)\n",
        "    num_train = int(math.ceil(num_videos * args.train_percent))\n",
        "    num_test = num_videos - num_train\n",
        "\n",
        "    print(\"Split breakdown: # total videos {}. # train videos {}. # test videos {}\".format(num_videos, num_train, num_test))\n",
        "    splits = []\n",
        "\n",
        "    for split_idx in range(args.num_splits):\n",
        "        train_keys, test_keys = split_random(keys, num_videos, num_train)\n",
        "        splits.append({\n",
        "            'train_keys': train_keys,\n",
        "            'test_keys': test_keys,\n",
        "            })\n",
        "\n",
        "    saveto = osp.join(args.save_dir, args.save_name + '.json')\n",
        "    write_json(splits, saveto)\n",
        "    print(\"Splits saved to {}\".format(saveto))\n",
        "\n",
        "    dataset.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create()"
      ]
    }
  ]
}