{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ0yKpsj/Fh5ibn/5PYGyV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyegupta12/videosummcolab/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh3rzhPR-LdG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "import argparse\n",
        "import h5py\n",
        "import json\n",
        "import torch.nn.init as init\n",
        "\n",
        "from config import  *\n",
        "from sys_utils import *\n",
        "from vsum_tools import  *\n",
        "from vasnet_model import  *\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname == 'Linear':\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.1)\n",
        "\n",
        "def parse_splits_filename(splits_filename):\n",
        "    # Parse split file and count number of k_folds\n",
        "    spath, sfname = os.path.split(splits_filename)\n",
        "    sfname, _ = os.path.splitext(sfname)\n",
        "    dataset_name = sfname.split('_')[0]  # Get dataset name e.g. tvsum\n",
        "    dataset_type = sfname.split('_')[1]  # augmentation type e.g. aug\n",
        "\n",
        "    # The keyword 'splits' is used as the filename fields terminator from historical reasons.\n",
        "    if dataset_type == 'splits':\n",
        "        # Split type is not present\n",
        "        dataset_type = ''\n",
        "\n",
        "    # Get number of discrete splits within each split json file\n",
        "    with open(splits_filename, 'r') as sf:\n",
        "        splits = json.load(sf)\n",
        "\n",
        "    return dataset_name, dataset_type, splits\n",
        "\n",
        "def lookup_weights_splits_file(path, dataset_name, dataset_type, split_id):\n",
        "    dataset_type_str = '' if dataset_type == '' else dataset_type + '_'\n",
        "    weights_filename = path + '/models/{}_{}splits_{}_*.tar.pth'.format(dataset_name, dataset_type_str, split_id)\n",
        "    weights_filename = glob.glob(weights_filename)\n",
        "    if len(weights_filename) == 0:\n",
        "        print(\"Couldn't find model weights: \", weights_filename)\n",
        "        return ''\n",
        "\n",
        "    # Get the first weights file in the dir\n",
        "    weights_filename = weights_filename[0]\n",
        "    splits_file = path + '/splits/{}_{}splits.json'.format(dataset_name, dataset_type_str)\n",
        "\n",
        "    return weights_filename, splits_file\n",
        "\n",
        "\n",
        "class AONet:\n",
        "\n",
        "    def __init__(self, hps: HParameters):\n",
        "        self.hps = hps\n",
        "        self.model = None\n",
        "        self.log_file = None\n",
        "        self.verbose = hps.verbose\n",
        "\n",
        "\n",
        "    def fix_keys(self, keys, dataset_name = None):\n",
        "        \"\"\"\n",
        "        :param keys:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # dataset_name = None\n",
        "        if len(self.datasets) == 1:\n",
        "            dataset_name = next(iter(self.datasets))\n",
        "\n",
        "        keys_out = []\n",
        "        for key in keys:\n",
        "            t = key.split('/')\n",
        "            if len(t) != 2:\n",
        "                assert dataset_name is not None, \"ERROR dataset name in some keys is missing but there are multiple dataset {} to choose from\".format(len(self.datasets))\n",
        "\n",
        "                key_name = dataset_name+'/'+key\n",
        "                keys_out.append(key_name)\n",
        "            else:\n",
        "                keys_out.append(key)\n",
        "\n",
        "        return keys_out\n",
        "\n",
        "\n",
        "    def load_datasets(self, datasets = None):\n",
        "        \"\"\"\n",
        "        Loads all h5 datasets from the datasets list into a dictionary self.dataset\n",
        "        referenced by their base filename\n",
        "        :param datasets:  List of dataset filenames\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if datasets is None:\n",
        "            datasets = self.hps.datasets\n",
        "\n",
        "        datasets_dict = {}\n",
        "        for dataset in datasets:\n",
        "            _, base_filename = os.path.split(dataset)\n",
        "            base_filename, _ = os.path.splitext(base_filename)\n",
        "            print(\"Loading:\", dataset)\n",
        "            # dataset_name = base_filename.split('_')[2]\n",
        "            # print(\"\\tDataset name:\", dataset_name)\n",
        "            datasets_dict[base_filename] = h5py.File(dataset, 'r')\n",
        "\n",
        "        self.datasets = datasets_dict\n",
        "        return datasets_dict\n",
        "\n",
        "\n",
        "    def load_split_file(self, splits_file):\n",
        "\n",
        "        self.dataset_name, self.dataset_type, self.splits = parse_splits_filename(splits_file)\n",
        "        n_folds = len(self.splits)\n",
        "        self.split_file = splits_file\n",
        "        print(\"Loading splits from: \",splits_file)\n",
        "\n",
        "        return n_folds\n",
        "\n",
        "\n",
        "    def select_split(self, split_id):\n",
        "        print(\"Selecting split: \",split_id)\n",
        "\n",
        "        self.split_id = split_id\n",
        "        n_folds = len(self.splits)\n",
        "        assert self.split_id < n_folds, \"split_id (got {}) exceeds {}\".format(self.split_id, n_folds)\n",
        "\n",
        "        split = self.splits[self.split_id]\n",
        "        self.train_keys = split['train_keys']\n",
        "        self.test_keys = split['test_keys']\n",
        "\n",
        "        dataset_filename = self.hps.get_dataset_by_name(self.dataset_name)[0]\n",
        "        _,dataset_filename = os.path.split(dataset_filename)\n",
        "        dataset_filename,_ = os.path.splitext(dataset_filename)\n",
        "        self.train_keys = self.fix_keys(self.train_keys, dataset_filename)\n",
        "        self.test_keys = self.fix_keys(self.test_keys, dataset_filename)\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "    def load_model(self, model_filename):\n",
        "        self.model.load_state_dict(torch.load(model_filename, map_location=lambda storage, loc: storage))\n",
        "        return\n",
        "\n",
        "\n",
        "    def initialize(self, cuda_device=None):\n",
        "        rnd_seed = 12345\n",
        "        random.seed(rnd_seed)\n",
        "        np.random.seed(rnd_seed)\n",
        "        torch.manual_seed(rnd_seed)\n",
        "\n",
        "        self.model = VASNet()\n",
        "        self.model.eval()\n",
        "        self.model.apply(weights_init)\n",
        "        #print(self.model)\n",
        "\n",
        "        cuda_device = cuda_device or self.hps.cuda_device\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            print(\"Setting CUDA device: \",cuda_device)\n",
        "            torch.cuda.set_device(cuda_device)\n",
        "            torch.cuda.manual_seed(rnd_seed)\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            self.model.cuda()\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def get_data(self, key):\n",
        "        key_parts = key.split('/')\n",
        "        assert len(key_parts) == 2, \"ERROR. Wrong key name: \"+key\n",
        "        dataset, key = key_parts\n",
        "        return self.datasets[dataset][key]\n",
        "\n",
        "    def lookup_weights_file(self, data_path):\n",
        "        dataset_type_str = '' if self.dataset_type == '' else self.dataset_type + '_'\n",
        "        weights_filename = data_path + '/models/{}_{}splits_{}_*.tar.pth'.format(self.dataset_name, dataset_type_str, self.split_id)\n",
        "        weights_filename = glob.glob(weights_filename)\n",
        "        if len(weights_filename) == 0:\n",
        "            print(\"Couldn't find model weights: \", weights_filename)\n",
        "            return ''\n",
        "\n",
        "        # Get the first weights filename in the dir\n",
        "        weights_filename = weights_filename[0]\n",
        "        splits_file = data_path + '/splits/{}_{}splits.json'.format(self.dataset_name, dataset_type_str)\n",
        "\n",
        "        return weights_filename, splits_file\n",
        "\n",
        "\n",
        "    def train(self, output_dir='EX-0'):\n",
        "\n",
        "        print(\"Initializing VASNet model and optimizer...\")\n",
        "        self.model.train()\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        if self.hps.use_cuda:\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "        max_val_fscore = 0\n",
        "        max_val_fscore_epoch = 0\n",
        "        train_keys = self.train_keys[:]\n",
        "\n",
        "        lr = self.hps.lr[0]\n",
        "        for epoch in range(self.hps.epochs_max):\n",
        "\n",
        "            print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='')\n",
        "            self.model.train()\n",
        "            avg_loss = []\n",
        "\n",
        "            random.shuffle(train_keys)\n",
        "\n",
        "            for i, key in enumerate(train_keys):\n",
        "                dataset = self.get_data(key)\n",
        "                seq = dataset['features'][...]\n",
        "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
        "                target = dataset['gtscore'][...]\n",
        "                target = torch.from_numpy(target).unsqueeze(0)\n",
        "\n",
        "                # Normalize frame scores\n",
        "                target -= target.min()\n",
        "                target /= target.max()\n",
        "\n",
        "                if self.hps.use_cuda:\n",
        "                    seq, target = seq.float().cuda(), target.float().cuda()\n",
        "\n",
        "                seq_len = seq.shape[1]\n",
        "                y, _ = self.model(seq,seq_len)\n",
        "                loss_att = 0\n",
        "\n",
        "                loss = criterion(y, target)\n",
        "                # loss2 = y.sum()/seq_len\n",
        "                loss = loss + loss_att\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                avg_loss.append([float(loss), float(loss_att)])\n",
        "\n",
        "            # Evaluate test dataset\n",
        "            val_fscore, video_scores = self.eval(self.test_keys)\n",
        "            if max_val_fscore < val_fscore:\n",
        "                max_val_fscore = val_fscore\n",
        "                max_val_fscore_epoch = epoch\n",
        "\n",
        "            avg_loss = np.array(avg_loss)\n",
        "            print(\"   Train loss: {0:.05f}\".format(np.mean(avg_loss[:, 0])), end='')\n",
        "            print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))\n",
        "\n",
        "            if self.verbose:\n",
        "                video_scores = [[\"No\", \"Video\", \"F-score\"]] + video_scores\n",
        "                print_table(video_scores, cell_width=[3,40,8])\n",
        "\n",
        "            # Save model weights\n",
        "            path, filename = os.path.split(self.split_file)\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            path = os.path.join(output_dir, 'models_temp', base_filename+'_'+str(self.split_id))\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "            filename = str(epoch)+'_'+str(round(val_fscore*100,3))+'.pth.tar'\n",
        "            torch.save(self.model.state_dict(), os.path.join(path, filename))\n",
        "\n",
        "        return max_val_fscore, max_val_fscore_epoch\n",
        "\n",
        "\n",
        "    def eval(self, keys, results_filename=None):\n",
        "\n",
        "        self.model.eval()\n",
        "        summary = {}\n",
        "        att_vecs = {}\n",
        "        with torch.no_grad():\n",
        "            for i, key in enumerate(keys):\n",
        "                data = self.get_data(key)\n",
        "                # seq = self.dataset[key]['features'][...]\n",
        "                seq = data['features'][...]\n",
        "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
        "\n",
        "                if self.hps.use_cuda:\n",
        "                    seq = seq.float().cuda()\n",
        "\n",
        "                y, att_vec = self.model(seq, seq.shape[1])\n",
        "                summary[key] = y[0].detach().cpu().numpy()\n",
        "                att_vecs[key] = att_vec.detach().cpu().numpy()\n",
        "\n",
        "        f_score, video_scores = self.eval_summary(summary, keys, metric=self.dataset_name,\n",
        "                    results_filename=results_filename, att_vecs=att_vecs)\n",
        "\n",
        "        return f_score, video_scores\n",
        "\n",
        "\n",
        "    def eval_summary(self, machine_summary_activations, test_keys, results_filename=None, metric='tvsum', att_vecs=None):\n",
        "\n",
        "        eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
        "\n",
        "        if results_filename is not None:\n",
        "            h5_res = h5py.File(results_filename, 'w')\n",
        "\n",
        "        fms = []\n",
        "        video_scores = []\n",
        "        for key_idx, key in enumerate(test_keys):\n",
        "            d = self.get_data(key)\n",
        "            probs = machine_summary_activations[key]\n",
        "\n",
        "            if 'change_points' not in d:\n",
        "                print(\"ERROR: No change points in dataset/video \",key)\n",
        "\n",
        "            cps = d['change_points'][...]\n",
        "            num_frames = d['n_frames'][()]\n",
        "            nfps = d['n_frame_per_seg'][...].tolist()\n",
        "            positions = d['picks'][...]\n",
        "            user_summary = d['user_summary'][...]\n",
        "\n",
        "            machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
        "            fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
        "            fms.append(fm)\n",
        "\n",
        "            # Reporting & logging\n",
        "            video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fm)])\n",
        "\n",
        "            if results_filename:\n",
        "                gt = d['gtscore'][...]\n",
        "                h5_res.create_dataset(key + '/score', data=probs)\n",
        "                h5_res.create_dataset(key + '/machine_summary', data=machine_summary)\n",
        "                h5_res.create_dataset(key + '/gtscore', data=gt)\n",
        "                h5_res.create_dataset(key + '/fm', data=fm)\n",
        "                h5_res.create_dataset(key + '/picks', data=positions)\n",
        "\n",
        "                video_name = key.split('/')[1]\n",
        "                if 'video_name' in d:\n",
        "                    video_name = d['video_name'][...]\n",
        "                h5_res.create_dataset(key + '/video_name', data=video_name)\n",
        "\n",
        "                if att_vecs is not None:\n",
        "                    h5_res.create_dataset(key + '/att', data=att_vecs[key])\n",
        "\n",
        "        mean_fm = np.mean(fms)\n",
        "\n",
        "        # Reporting & logging\n",
        "        if results_filename is not None:\n",
        "            h5_res.close()\n",
        "\n",
        "        return mean_fm, video_scores\n",
        "\n",
        "\n",
        "#==============================================================================================\n",
        "\n",
        "\n",
        "\n",
        "def eval_split(hps, splits_filename, data_dir='test'):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    ao = AONet(hps)\n",
        "    ao.initialize()\n",
        "    ao.load_datasets()\n",
        "    ao.load_split_file(splits_filename)\n",
        "\n",
        "    val_fscores = []\n",
        "    for split_id in range(len(ao.splits)):\n",
        "        ao.select_split(split_id)\n",
        "        weights_filename, _ = ao.lookup_weights_file(data_dir)\n",
        "        print(\"Loading model:\", weights_filename)\n",
        "        ao.load_model(weights_filename)\n",
        "        val_fscore, video_scores = ao.eval(ao.test_keys)\n",
        "        val_fscores.append(val_fscore)\n",
        "\n",
        "        val_fscore_avg = np.mean(val_fscores)\n",
        "\n",
        "        if hps.verbose:\n",
        "            video_scores = [[\"No.\", \"Video\", \"F-score\"]] + video_scores\n",
        "            print_table(video_scores, cell_width=[4,45,5])\n",
        "\n",
        "        print(\"Avg F-score: \", val_fscore)\n",
        "        print(\"\")\n",
        "\n",
        "    print(\"Total AVG F-score: \", val_fscore_avg)\n",
        "    return val_fscore_avg\n",
        "\n",
        "\n",
        "def train(hps):\n",
        "    os.makedirs(hps.output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'splits'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'code'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(hps.output_dir, 'models'), exist_ok=True)\n",
        "    os.system('cp -f splits/*.json  ' + hps.output_dir + '/splits/')\n",
        "    os.system('cp *.py ' + hps.output_dir + '/code/')\n",
        "\n",
        "    # Create a file to collect results from all splits\n",
        "    f = open(hps.output_dir + '/results.txt', 'wt')\n",
        "\n",
        "    for split_filename in hps.splits:\n",
        "        dataset_name, dataset_type, splits = parse_splits_filename(split_filename)\n",
        "\n",
        "        # For no augmentation use only a dataset corresponding to the split file\n",
        "        datasets = None\n",
        "        if dataset_type == '':\n",
        "            datasets = hps.get_dataset_by_name(dataset_name)\n",
        "\n",
        "        if datasets is None:\n",
        "            datasets = hps.datasets\n",
        "\n",
        "        f_avg = 0\n",
        "        n_folds = len(splits)\n",
        "        for split_id in range(n_folds):\n",
        "            ao = AONet(hps)\n",
        "            ao.initialize()\n",
        "            ao.load_datasets(datasets=datasets)\n",
        "            ao.load_split_file(splits_file=split_filename)\n",
        "            ao.select_split(split_id=split_id)\n",
        "\n",
        "            fscore, fscore_epoch = ao.train(output_dir=hps.output_dir)\n",
        "            f_avg += fscore\n",
        "\n",
        "            # Log F-score for this split_id\n",
        "            f.write(split_filename + ', ' + str(split_id) + ', ' + str(fscore) + ', ' + str(fscore_epoch) + '\\n')\n",
        "            f.flush()\n",
        "\n",
        "            # Save model with the highest F score\n",
        "            _, log_file = os.path.split(split_filename)\n",
        "            log_dir, _ = os.path.splitext(log_file)\n",
        "            log_dir += '_' + str(split_id)\n",
        "            log_file = os.path.join(hps.output_dir, 'models', log_dir) + '_' + str(fscore) + '.tar.pth'\n",
        "\n",
        "            os.makedirs(os.path.join(hps.output_dir, 'models', ), exist_ok=True)\n",
        "            os.system('mv ' + hps.output_dir + '/models_temp/' + log_dir + '/' + str(fscore_epoch) + '_*.pth.tar ' + log_file)\n",
        "            os.system('rm -rf ' + hps.output_dir + '/models_temp/' + log_dir)\n",
        "\n",
        "            print(\"Split: {0:}   Best F-score: {1:0.5f}   Model: {2:}\".format(split_filename, fscore, log_file))\n",
        "\n",
        "        # Write average F-score for all splits to the results.txt file\n",
        "        f_avg /= n_folds\n",
        "        f.write(split_filename + ', ' + str('avg') + ', ' + str(f_avg) + '\\n')\n",
        "        f.flush()\n",
        "\n",
        "    f.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print_pkg_versions()\n",
        "\n",
        "    parser = argparse.ArgumentParser(\"PyTorch implementation of paper \\\"Summarizing Videos with Attention\\\"\")\n",
        "    parser.add_argument('-r', '--root', type=str, default='', help=\"Project root directory\")\n",
        "    parser.add_argument('-d', '--datasets', type=str, help=\"Path to a comma separated list of h5 datasets\")\n",
        "    parser.add_argument('-s', '--splits', type=str, help=\"Comma separated list of split files.\")\n",
        "    parser.add_argument('-t', '--train', action='store_true', help=\"Train\")\n",
        "    parser.add_argument('-v', '--verbose', action='store_true', help=\"Prints out more messages\")\n",
        "    parser.add_argument('-o', '--output-dir', type=str, default='data', help=\"Experiment name\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # MAIN\n",
        "    #======================\n",
        "    hps = HParameters()\n",
        "    hps.load_from_args(args.__dict__)\n",
        "\n",
        "    print(\"Parameters:\")\n",
        "    print(\"----------------------------------------------------------------------\")\n",
        "    print(hps)\n",
        "\n",
        "    if hps.train:\n",
        "        train(hps)\n",
        "    else:\n",
        "        results=[['No', 'Split', 'Mean F-score']]\n",
        "        for i, split_filename in enumerate(hps.splits):\n",
        "            f_score = eval_split(hps, split_filename, data_dir=hps.output_dir)\n",
        "            results.append([i+1, split_filename, str(round(f_score * 100.0, 3))+\"%\"])\n",
        "\n",
        "        print(\"\\nFinal Results:\")\n",
        "        print_table(results)\n",
        "\n",
        "\n",
        "    sys.exit(0)"
      ]
    }
  ]
}